{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dcb990-a25a-4f98-9fee-00a0846928bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# Import Libraries (All Levels)\n",
    "# =================================================================================\n",
    "import numpy as np  # Numerical computing\n",
    "import pandas as pd  # Data manipulation\n",
    "from sklearn import datasets  # Built-in datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # Data splitting/validation\n",
    "from sklearn.preprocessing import StandardScaler  # Feature scaling\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN algorithm\n",
    "from sklearn.naive_bayes import GaussianNB  # Naive Bayes algorithm\n",
    "from sklearn.metrics import accuracy_score, classification_report  # Evaluation metrics\n",
    "import matplotlib.pyplot as plt  # Visualization\n",
    "from matplotlib.colors import ListedColormap  # Custom color maps for accessibility\n",
    "\n",
    "# =================================================================================\n",
    "# 1. Load Data (Novice-Friendly)\n",
    "# =================================================================================\n",
    "# [Novice]: The Iris dataset contains measurements of 150 iris flowers (3 species).\n",
    "# We use it because it's simple and helps learn classification basics.\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # Features: sepal length/width, petal length/width\n",
    "y = iris.target  # Labels: 0=setosa, 1=versicolor, 2=virginica\n",
    "\n",
    "# =================================================================================\n",
    "# 2. Split Data (Intermediate)\n",
    "# =================================================================================\n",
    "# [Intermediate]: Stratified splitting preserves class distribution in train/test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,  # Ensures reproducibility\n",
    "    stratify=y  # Balances class distribution\n",
    ")\n",
    "\n",
    "# =================================================================================\n",
    "# 3. Feature Scaling (Expert Note)\n",
    "# =================================================================================\n",
    "# [Expert]: KNN is distance-based; scaling ensures features contribute equally.\n",
    "# StandardScaler transforms data to mean=0, std=1. Fit only on training data.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit to training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Apply to test data\n",
    "\n",
    "# =================================================================================\n",
    "# 4. K-Nearest Neighbors (KNN) (All Levels)\n",
    "# =================================================================================\n",
    "# [Novice]: KNN predicts labels based on the majority of nearest neighbors.\n",
    "# [Intermediate]: K=3 means we consider the 3 closest data points.\n",
    "# [Expert]: Complexity O(nd) for prediction, where n=samples, d=features.\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)  # Train model on scaled data\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# =================================================================================\n",
    "# 5. Gaussian Naive Bayes (Technical Deep Dive)\n",
    "# =================================================================================\n",
    "# [Novice]: Uses probability to predict classes (fast but assumes feature independence).\n",
    "# [Expert]: Applies Bayes' theorem with Gaussian likelihood:\n",
    "# P(y|x) ∝ P(x|y) * P(y), where P(x|y) ~ N(μ_y, σ_y²)\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)  # No scaling needed for Naive Bayes\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# =================================================================================\n",
    "# 6. Cross-Validation (Intermediate/Expert)\n",
    "# =================================================================================\n",
    "# [Intermediate]: 5-fold CV averages performance across different data splits.\n",
    "# [Expert]: Prevents overfitting; use StratifiedKFold for class imbalance.\n",
    "cv_knn = cross_val_score(knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "cv_nb = cross_val_score(naive_bayes, X, y, cv=5, scoring='accuracy').mean()\n",
    "print(f\"\\nCross-Validation Scores:\\nKNN: {cv_knn:.4f}, Naive Bayes: {cv_nb:.4f}\")\n",
    "\n",
    "# =================================================================================\n",
    "# 7. Visualization (Accessibility-First)\n",
    "# =================================================================================\n",
    "# [Novice]: We visualize decision boundaries to see how models separate classes.\n",
    "# [Accessibility]: Colorblind-friendly palettes (avoid red-green), high-contrast labels.\n",
    "\n",
    "# Prepare 2D data (using first two features for simplicity)\n",
    "X_train_2d = X_train[:, :2]  # Sepal length/width only\n",
    "X_test_2d = X_test[:, :2]\n",
    "\n",
    "# Re-train models on 2D data (for visualization only)\n",
    "knn_2d = KNeighborsClassifier(n_neighbors=3).fit(X_train_2d, y_train)\n",
    "nb_2d = GaussianNB().fit(X_train_2d, y_train)\n",
    "\n",
    "# Create meshgrid for decision boundaries\n",
    "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# Accessibility: Colorblind-friendly colormaps (blue, orange, teal)\n",
    "cmap = ListedColormap(['#1f77b4', '#ff7f0e', '#2ca02c'])  # Blue, Orange, Green\n",
    "cmap_light = ListedColormap(['#a1c9f4', '#ffd699', '#b2e2b2'])  # Light versions\n",
    "\n",
    "plt.figure(figsize=(14, 6), dpi=100)  # High-resolution figure\n",
    "\n",
    "# Plot KNN boundaries\n",
    "plt.subplot(1, 2, 1)\n",
    "Z_knn = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_knn, alpha=0.4, cmap=cmap_light)\n",
    "plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap=cmap, edgecolor='k', s=50)\n",
    "plt.title(\"KNN Decision Boundaries (2D)\", fontsize=14, pad=20)\n",
    "plt.xlabel('Sepal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Sepal Width (cm)', fontsize=12)\n",
    "\n",
    "# Plot Naive Bayes boundaries\n",
    "plt.subplot(1, 2, 2)\n",
    "Z_nb = nb_2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z_nb, alpha=0.4, cmap=cmap_light)\n",
    "scatter = plt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap=cmap, edgecolor='k', s=50)\n",
    "plt.title(\"Naive Bayes Decision Boundaries (2D)\", fontsize=14, pad=20)\n",
    "plt.xlabel('Sepal Length (cm)', fontsize=12)\n",
    "\n",
    "# Add universal legend with proper argument handling\n",
    "handles, _ = scatter.legend_elements(prop=\"colors\")  # Explicitly get color handles\n",
    "plt.legend(\n",
    "    handles=handles,\n",
    "    title='Species',\n",
    "    labels=['Setosa', 'Versicolor', 'Virginica'],  # Custom labels for clarity\n",
    "    loc='lower right',\n",
    "    framealpha=0.9,  # High contrast background\n",
    "    edgecolor='black'  # Added border for better visibility\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot as a PNG file (high resolution, accessible colors)\n",
    "plt.savefig(\n",
    "    'KNN vs Naive.png',  # File name\n",
    "    dpi=300,                    # High resolution for clarity\n",
    "    bbox_inches='tight',        # Prevent cropping\n",
    "    facecolor='white'           # Accessible background\n",
    ")\n",
    "\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
